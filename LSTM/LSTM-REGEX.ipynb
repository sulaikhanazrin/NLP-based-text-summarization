{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ef3d76-f77d-4630-85fa-10727d12bc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sulai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sulai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sulai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sulai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    01 dec 2021 05:30 pm accident occurred thiruva...\n",
      "1    31 dec 2024 06:30 accident occurred thiruvanan...\n",
      "2    24 dec 2024 08:45 accident occurred thiruvanan...\n",
      "3    01 jan 2023 02:15 pm accident occurred thiruva...\n",
      "4    17 jan 2024 05:45 pm accident occurred thiruva...\n",
      "Name: Cleaned Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data files (only need to do this once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sulai\\Downloads\\final_accident_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data files (only need to do this once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation except for specific characters (e.g., ':')\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation.replace(':', '')))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Keep numbers and FIR numbers (e.g., P21, P18)\n",
    "    tokens = [word for word in tokens if re.match(r'\\d+|p\\d+|:\\d+|[a-zA-Z]+', word)]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the cleaning function to the unstructured text column\n",
    "df['Cleaned Text'] = df['Unstructured Text'].apply(clean_text)\n",
    "\n",
    "# Save the cleaned data back to the same CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Example of cleaned text\n",
    "print(df['Cleaned Text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ce23c7-9f65-416c-9263-ca3684e0b0c5",
   "metadata": {},
   "source": [
    "# Text Preprocessing for Accident Reports\n",
    "\n",
    "## Overview\n",
    "This script processes accident report data by cleaning and structuring the text for further analysis.\n",
    "\n",
    "## Steps Involved\n",
    "\n",
    "### 1. Loading the Dataset\n",
    "- Reads a CSV file (`final_accident_data.csv`) containing accident reports.\n",
    "- Assumes the dataset has a column named **\"Unstructured Text\"**, which contains raw accident descriptions.\n",
    "\n",
    "### 2. Cleaning the Text\n",
    "- **Converts to Lowercase**: Ensures uniformity by making all words lowercase.\n",
    "- **Removes Punctuation**: Eliminates unnecessary symbols except for colons (`:`).\n",
    "- **Tokenization**: Breaks the text into individual words (tokens).\n",
    "- **Removes Stopwords**: Filters out common words (e.g., \"the\", \"is\", \"and\") that do not contribute much meaning.\n",
    "- **Retains Relevant Numbers and FIR Patterns**: Keeps numbers, specific patterns like `P21`, and time-related values (`:15`).\n",
    "- **Reconstructs Cleaned Text**: Joins the processed words back into a cleaned sentence.\n",
    "\n",
    "### 3. Saving and Displaying Results\n",
    "- Stores the cleaned text in a new column (**\"Cleaned Text\"**) in the same dataset.\n",
    "- Saves the updated CSV file.\n",
    "- Prints a few examples of cleaned text for verification.\n",
    "\n",
    "## Purpose\n",
    "This preprocessing prepares the text for further NLP tasks like classification, summarization, or chatbot integration by reducing noise while preserving key information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d9f0412-b006-4652-9159-c21e321927ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add <start> and <end> tokens to the cleaned text and recommendation columns\n",
    "df['Cleaned Text'] = df['Cleaned Text'].apply(lambda x: '<start> ' + x + ' <end>')\n",
    "df['Recommendation'] = df['Recommendation'].apply(lambda x: '<start> ' + x + ' <end>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a72f8-9160-413e-b245-427f359144f7",
   "metadata": {},
   "source": [
    "# Adding Start and End Tokens to Processed Text\n",
    "\n",
    "## Overview\n",
    "This step enhances the dataset by adding special tokens (`<start>` and `<end>`) to mark the beginning and end of sentences in two key columns: **\"Cleaned Text\"** and **\"Recommendation\"**.\n",
    "\n",
    "## Purpose of Start and End Tokens\n",
    "- **Improves NLP Models**: Helps models understand sentence boundaries.\n",
    "- **Useful for Seq2Seq Models**: Essential for training models like LSTMs or Transformers in text generation tasks.\n",
    "- **Enhances Data Consistency**: Ensures structured input for processing.\n",
    "\n",
    "## Implementation Details\n",
    "- The **\"Cleaned Text\"** column is updated by adding:\n",
    "  - `<start>` at the beginning.\n",
    "  - `<end>` at the end.\n",
    "- The **\"Recommendation\"** column is processed similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a08cfbb9-6936-4156-8d12-5f9179015571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenizer for input (Cleaned Text) and output (Recommendation)\n",
    "tokenizer = Tokenizer(oov_token='<unk>')\n",
    "tokenizer.fit_on_texts(df['Cleaned Text'].tolist() + df['Recommendation'].tolist())\n",
    "\n",
    "# Convert text to sequences\n",
    "input_sequences = tokenizer.texts_to_sequences(df['Cleaned Text'])\n",
    "output_sequences = tokenizer.texts_to_sequences(df['Recommendation'])\n",
    "\n",
    "# Padding sequences\n",
    "max_len_input = 200  # Max length for input sequences\n",
    "max_len_output = 50  # Max length for output sequences\n",
    "input_padded = pad_sequences(input_sequences, maxlen=max_len_input, padding='post', truncating='post')\n",
    "output_padded = pad_sequences(output_sequences, maxlen=max_len_output, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de23d9fe-5528-4667-bc5b-7d21ba15ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_padded, output_padded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c0f58-f66e-4970-8233-62033184c510",
   "metadata": {},
   "source": [
    "# Tokenization and Sequence Preparation for NLP Model\n",
    "\n",
    "## Overview\n",
    "This step processes textual data by tokenizing, converting to sequences, padding, and splitting into training and testing datasets.\n",
    "\n",
    "## Steps Involved:\n",
    "\n",
    "### 1. **Tokenization**\n",
    "- A `Tokenizer` is created to convert words into numerical representations.\n",
    "- The special token `<unk>` is used for out-of-vocabulary (OOV) words.\n",
    "- The tokenizer is trained on both the **\"Cleaned Text\"** (input) and **\"Recommendation\"** (output) columns.\n",
    "\n",
    "### 2. **Text to Sequence Conversion**\n",
    "- Each sentence in **\"Cleaned Text\"** and **\"Recommendation\"** is transformed into a sequence of numerical tokens.\n",
    "\n",
    "### 3. **Padding Sequences**\n",
    "- Since different sentences have different lengths, padding ensures consistency.\n",
    "- **Maximum sequence length**:\n",
    "  - **Input text:** 200 tokens\n",
    "  - **Output text:** 50 tokens\n",
    "- Padding is applied **post-sequence**, ensuring shorter sequences do not affect model processing.\n",
    "\n",
    "### 4. **Splitting Dataset**\n",
    "- The data is divided into **training (80%)** and **testing (20%)** sets.\n",
    "- Ensures proper evaluation of the NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3327514-b2b0-456e-87ef-8289da7020ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">411,900</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">411,900</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]        │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]        │                 │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4119</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,058,583</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │         \u001b[38;5;34m411,900\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │         \u001b[38;5;34m411,900\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │         \u001b[38;5;34m365,568\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│                               │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]        │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,  │         \u001b[38;5;34m365,568\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                               │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]        │                 │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m4119\u001b[0m)          │       \u001b[38;5;34m1,058,583\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,613,519</span> (9.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,613,519\u001b[0m (9.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,789,719</span> (6.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,789,719\u001b[0m (6.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">823,800</span> (3.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m823,800\u001b[0m (3.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 378ms/step - loss: 4.9468 - val_loss: 0.4753\n",
      "Epoch 2/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 363ms/step - loss: 0.4415 - val_loss: 0.3441\n",
      "Epoch 3/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 370ms/step - loss: 0.3241 - val_loss: 0.2419\n",
      "Epoch 4/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 352ms/step - loss: 0.2234 - val_loss: 0.1485\n",
      "Epoch 5/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 327ms/step - loss: 0.1361 - val_loss: 0.0926\n",
      "Epoch 6/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 330ms/step - loss: 0.0890 - val_loss: 0.0640\n",
      "Epoch 7/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 328ms/step - loss: 0.0625 - val_loss: 0.0489\n",
      "Epoch 8/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 320ms/step - loss: 0.0479 - val_loss: 0.0381\n",
      "Epoch 9/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 336ms/step - loss: 0.0369 - val_loss: 0.0325\n",
      "Epoch 10/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 345ms/step - loss: 0.0334 - val_loss: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "import pickle\n",
    "\n",
    "# Load GloVe embeddings\n",
    "glove_file = r\"C:\\Users\\sulai\\Downloads\\NLP\\glove.6B.100d.txt\"\n",
    "embeddings_index = {}\n",
    "with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "# Create embedding matrix\n",
    "embedding_dim = 100  # Dimension of GloVe embeddings\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in embeddings_index:\n",
    "        embedding_matrix[i] = embeddings_index[word]\n",
    "\n",
    "# Define the model\n",
    "embedding_dim = 100  # Embedding dimension\n",
    "lstm_units = 256  # Number of LSTM units\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_len_input,))\n",
    "enc_emb = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)(encoder_inputs)\n",
    "encoder_lstm = LSTM(lstm_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_len_output - 1,))\n",
    "dec_emb = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)(decoder_inputs)\n",
    "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "# Prepare decoder input and output sequences\n",
    "decoder_input_data = output_padded[:, :-1]  # Exclude the last token\n",
    "decoder_output_data = output_padded[:, 1:]  # Exclude the first token\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train, decoder_input_data], \n",
    "    decoder_output_data, \n",
    "    epochs=10, \n",
    "    batch_size=64, \n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save('lstm_model.h5')\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fff9f3e-1225-4583-81ae-f6d488d0e313",
   "metadata": {},
   "source": [
    "# LSTM-Based Sequence-to-Sequence Model for Text Generation\n",
    "\n",
    "## Overview\n",
    "This step builds and trains an **LSTM-based sequence-to-sequence model** for accident report analysis.  \n",
    "It includes **GloVe embeddings**, an **encoder-decoder architecture**, and **sequence preparation**.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Loading Pretrained GloVe Embeddings**\n",
    "- GloVe (Global Vectors for Word Representation) embeddings are used to create word vectors.\n",
    "- The embeddings are loaded from a file (`glove.6B.100d.txt`) and stored in a dictionary.\n",
    "- An **embedding matrix** is created to map each word in the vocabulary to its corresponding GloVe vector.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Defining the Encoder-Decoder Architecture**\n",
    "### **Encoder**\n",
    "- **Input:** Preprocessed accident report text (`Cleaned Text`).\n",
    "- **Embedding Layer:** Uses **pretrained GloVe vectors**.\n",
    "- **LSTM Layer:** Processes text and captures **contextual information**.\n",
    "- **Hidden State & Cell State:** Passed to the decoder.\n",
    "\n",
    "### **Decoder**\n",
    "- **Input:** Recommendations (`Recommendation`).\n",
    "- **Embedding Layer:** Uses the same **GloVe embedding matrix**.\n",
    "- **LSTM Layer:** Generates sequential outputs with **attention to the encoder’s state**.\n",
    "- **Dense Layer:** Outputs predictions using a **softmax activation function**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Model Summary**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5819c18-1bc8-405e-93a3-42ddc90d284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have trained your model and it is stored in the variable `model`\n",
    "model.save('lstm_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dcc6153-b1f0-4eee-97f6-22baba8f5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define encoder and decoder models for inference\n",
    "encoder_model_inf = Model(encoder_inputs, [state_h, state_c])\n",
    "\n",
    "decoder_state_input_h = Input(shape=(lstm_units,))\n",
    "decoder_state_input_c = Input(shape=(lstm_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(dec_emb, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model_inf = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfac55b-8259-4194-8821-c7fb05887f25",
   "metadata": {},
   "source": [
    "# Inference Setup for Sequence-to-Sequence Model\n",
    "\n",
    "## **Overview**\n",
    "Once the LSTM-based **encoder-decoder model** is trained, we need to set up **separate models for inference**.  \n",
    "Inference models allow us to generate predictions **one word at a time**, using the encoder's output states as input for the decoder.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Defining the Encoder Model for Inference**\n",
    "- The **encoder** takes an input sequence and generates **hidden states** (`state_h`) and **cell states** (`state_c`).\n",
    "- These states will be used to initialize the **decoder** during inference.\n",
    "\n",
    "```python\n",
    "encoder_model_inf = Model(encoder_inputs, [state_h, state_c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3cab891-6f28-4a30-8a9c-2c2b10f1f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "patterns = {\n",
    "    'District': r'\\b(thiruvananthapuram city)\\b',\n",
    "    'PS Name': r'\\b(vattiyoorkavu|vanchiyoor)\\b',\n",
    "    'Date Report': r'\\b(\\d{2} [a-z]{3} \\d{4})\\b',\n",
    "    'Date Accident': r'\\b(\\d{2} [a-z]{3} \\d{4})\\b',\n",
    "    'Time Accident': r'\\b(\\d{1,2}:\\d{2} (?:am|pm))\\b',\n",
    "    'Accident type': r'\\baccident type (\\w+ injury|fatal)\\b',\n",
    "    'Death': r'\\b(\\d+) fatalities\\b',\n",
    "    'Grievous': r'\\b(\\d+) grievous injuries\\b',\n",
    "    'Minor': r'\\b(\\d+) minor injuries\\b',\n",
    "    'Pedestrian': r'\\b(\\d+) pedestrian\\b',\n",
    "    'Cyclist': r'\\b(\\d+) cyclist\\b',\n",
    "    'Place of Occurance': r'\\baccident took place (\\w+)\\b',\n",
    "    'Type Area': r'\\b(\\w+) area\\b',\n",
    "    'City/Town/Village': r'\\b(\\w+) (?:city|town|village)\\b',\n",
    "    'Lanes Road': r'\\b(\\w+) lanes\\b',\n",
    "    'Divider': r'\\bdivider (\\w+)\\b',\n",
    "    'Spot Accident': r'\\bspot classification (\\w+)\\b',\n",
    "    'Weather': r'\\bweather conditions (\\w+)\\b',\n",
    "    'Collision': r'\\bcollision (\\w+)\\b',\n",
    "    'Type Road': r'\\broad type (\\w+)\\b',\n",
    "    'Road Features': r'\\bfeatures (\\w+)\\b',\n",
    "    'Visibility': r'\\bvisibility (\\w+)\\b',\n",
    "    'Traffic Control': r'\\btraffic control scene (\\w+)\\b',\n",
    "    'Accussed Vehicle': r'\\baccident involved (\\w+)\\b',\n",
    "    'Victim Vehicle': r'\\b(\\w+) vehicle\\b',\n",
    "    'Recommendation': r'\\brecommendation (.+?)\\b'\n",
    "}\n",
    "\n",
    "with open('regex_patterns.json', 'w') as f:\n",
    "    json.dump(patterns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79a060d1-db49-4a08-98c6-58181ad21244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              District: thiruvananthapuram city\\nPS Name: vattiyoorkavu\\nDate Report: 01 dec 2021\\nDate Accident: 01 dec 2021\\nTime Accident: 05:30 pm\\nAccident type: minor injury\\nDeath: 0\\nGrievous: 0\\nMinor: 2\\nPlace of Occurance: moothakunnam\\nCity/Town/Village: thiruvananthapuram\\nSpot Accident: near\\nWeather: sunnyclear\\nType Road: national\\nRoad Features: straight\\nVisibility: road\\nTraffic Control: uncontrolled\\nAccussed Vehicle: tipper\\nRecommendation: improve\n",
      "1                                               District: thiruvananthapuram city\\nPS Name: vanchiyoor\\nDate Report: 31 dec 2024\\nDate Accident: 31 dec 2024\\nAccident type: fatal\\nDeath: 1\\nGrievous: 0\\nMinor: 0\\nPlace of Occurance: kavilnada\\nCity/Town/Village: thiruvananthapuram\\nSpot Accident: pedestrian\\nWeather: sunnyclear\\nType Road: national\\nRoad Features: straight\\nVisibility: road\\nTraffic Control: uncontrolled\\nAccussed Vehicle: motor\\nRecommendation: improve\n",
      "2    District: thiruvananthapuram city\\nPS Name: vanchiyoor\\nDate Report: 24 dec 2024\\nDate Accident: 24 dec 2024\\nAccident type: grevious injury\\nDeath: 0\\nGrievous: 1\\nMinor: 0\\nPlace of Occurance: vazhakulam\\nType Area: marketcommercial\\nCity/Town/Village: thiruvananthapuram\\nSpot Accident: marketcommercial\\nWeather: sunnyclear\\nType Road: state\\nRoad Features: straight\\nVisibility: road\\nTraffic Control: uncontrolled\\nAccussed Vehicle: motor\\nRecommendation: improve\n",
      "3                                     District: thiruvananthapuram city\\nPS Name: vanchiyoor\\nTime Accident: 02:15 pm\\nAccident type: grevious injury\\nDeath: 0\\nGrievous: 1\\nMinor: 0\\nPlace of Occurance: perumattam\\nType Area: marketcommercial\\nCity/Town/Village: thiruvananthapuram\\nSpot Accident: marketcommercial\\nWeather: sunnyclear\\nType Road: road\\nRoad Features: curved\\nVisibility: road\\nTraffic Control: uncontrolled\\nAccussed Vehicle: auto\\nRecommendation: improve\n",
      "4                                                                                District: thiruvananthapuram city\\nPS Name: vanchiyoor\\nTime Accident: 05:45 pm\\nAccident type: grevious injury\\nDeath: 0\\nGrievous: 1\\nMinor: 1\\nPlace of Occurance: near\\nCity/Town/Village: thiruvananthapuram\\nSpot Accident: near\\nWeather: sunnyclear\\nType Road: state\\nRoad Features: straight\\nVisibility: road\\nTraffic Control: uncontrolled\\nAccussed Vehicle: motor\\nRecommendation: improve\n",
      "Name: Formatted Summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def extract_info(text, patterns):\n",
    "    info = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            try:\n",
    "                info[key] = match.group(1).strip()  # Capture the actual data\n",
    "            except IndexError:\n",
    "                print(f\"Error in pattern for {key}: {pattern}\")\n",
    "                print(f\"Text: {text}\")\n",
    "                info[key] = None\n",
    "        else:\n",
    "            info[key] = None\n",
    "    return info\n",
    "\n",
    "# Apply the extraction function to each row in the DataFrame\n",
    "df['Summary'] = df['Cleaned Text'].apply(lambda x: extract_info(x, patterns))\n",
    "\n",
    "# Format the extracted information into a summary\n",
    "def format_summary(summary):\n",
    "    formatted_summary = []\n",
    "    for key, value in summary.items():\n",
    "        if value:\n",
    "            formatted_summary.append(f\"{key}: {value}\")\n",
    "    return \"\\n\".join(formatted_summary)\n",
    "\n",
    "# Apply the formatting function to each summary\n",
    "df['Formatted Summary'] = df['Summary'].apply(format_summary)\n",
    "\n",
    "# Adjust display settings to show full content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Print the summaries\n",
    "print(df['Formatted Summary'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fa06f1f-ca4d-47f9-a842-8785aaf718e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                        <start> 01 dec 2021 05:30 pm accident occurred thiruvananthapuram city jurisdiction vattiyoorkavu police station accident type minor injury 0 fatalities 0 grievous injuries 2 minor injuries accident took place moothakunnam rural weather conditions sunnyclear good visibility road type national highway features straight road accident involved tipper motor cycle spot classification near bus stop traffic control scene uncontrolled recommendation improve general road safety awareness enforcement <end>\n",
      "1    <start> 31 dec 2024 06:30 accident occurred thiruvananthapuram city jurisdiction vanchiyoor police station accident type fatal 1 fatalities 0 grievous injuries 0 minor injuries accident took place kavilnada rural weather conditions sunnyclear good visibility road type national highway features straight road accident involved motor cycle motor cycle spot classification pedestrian crossing traffic control scene uncontrolled recommendation improve pedestrian crossings install better signage increase road safety measures emergency response times <end>\n",
      "2                                                       <start> 24 dec 2024 08:45 accident occurred thiruvananthapuram city jurisdiction vanchiyoor police station accident type grevious injury 0 fatalities 1 grievous injuries 0 minor injuries accident took place vazhakulam rural weather conditions sunnyclear good visibility road type state highway features straight road accident involved motor cycle scooter spot classification marketcommercial area traffic control scene uncontrolled recommendation improve general road safety awareness enforcement <end>\n",
      "3                                                         <start> 01 jan 2023 02:15 pm accident occurred thiruvananthapuram city jurisdiction vanchiyoor police station accident type grevious injury 0 fatalities 1 grievous injuries 0 minor injuries accident took place perumattam rural weather conditions sunnyclear good visibility road type road features curved road accident involved auto rickshaw motor cycle spot classification marketcommercial area traffic control scene uncontrolled recommendation improve general road safety awareness enforcement <end>\n",
      "4                                        <start> 17 jan 2024 05:45 pm accident occurred thiruvananthapuram city jurisdiction vanchiyoor police station accident type grevious injury 0 fatalities 1 grievous injuries 1 minor injuries accident took place near federal bank vazhakulam rural weather conditions sunnyclear good visibility road type state highway features straight road accident involved motor cycle car spot classification near office complex traffic control scene uncontrolled recommendation improve general road safety awareness enforcement <end>\n",
      "Name: Cleaned Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the cleaned text\n",
    "print(df['Cleaned Text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4382fe54-5c6a-4096-a2e1-1e0294f8816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Accident type: accident type\\nGrievous: grievo...\n",
      "1    Accident type: accident type\\nGrievous: grievo...\n",
      "2    Accident type: accident type\\nGrievous: grievo...\n",
      "3    Accident type: accident type\\nGrievous: grievo...\n",
      "4    Accident type: accident type\\nGrievous: grievo...\n",
      "Name: Formatted Summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Example of how to format the summary\n",
    "def format_summary(summary):\n",
    "    formatted_summary = []\n",
    "    for key, value in summary.items():\n",
    "        if value:\n",
    "            formatted_summary.append(f\"{key}: {value}\")\n",
    "    return \"\\n\".join(formatted_summary)\n",
    "\n",
    "# Apply the formatting function to each summary\n",
    "df['Formatted Summary'] = df['Summary'].apply(format_summary)\n",
    "\n",
    "# Display the first few summaries\n",
    "print(df['Formatted Summary'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5e6ef57-3fec-493f-af4f-4d5a4cc98bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                        Accident type: accident type\\nGrievous: grievous\\nMinor: minor\\nWeather: weather\\nVisibility: visibility\\nTraffic Control: traffic control\\nRecommendation: recommendation\n",
      "1                                Accident type: accident type\\nGrievous: grievous\\nMinor: minor\\nPedestrian: pedestrian\\nWeather: weather\\nVisibility: visibility\\nTraffic Control: traffic control\\nRecommendation: recommendation\n",
      "2                                                        Accident type: accident type\\nGrievous: grievous\\nMinor: minor\\nWeather: weather\\nVisibility: visibility\\nTraffic Control: traffic control\\nRecommendation: recommendation\n",
      "3    Accident type: accident type\\nGrievous: grievous\\nMinor: minor\\nWeather: weather\\nType Road: type road\\nRoad Features: road features\\nVisibility: visibility\\nTraffic Control: traffic control\\nRecommendation: recommendation\n",
      "4                                                        Accident type: accident type\\nGrievous: grievous\\nMinor: minor\\nWeather: weather\\nVisibility: visibility\\nTraffic Control: traffic control\\nRecommendation: recommendation\n",
      "Name: Formatted Summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the display option to show more characters in each cell\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None to display the full content\n",
    "\n",
    "# Now print the summaries\n",
    "print(df['Formatted Summary'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd5ae6-7e92-483c-ad5f-c3f0585fd022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpu_env]",
   "language": "python",
   "name": "conda-env-gpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
