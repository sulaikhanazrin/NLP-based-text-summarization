{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ef3d76-f77d-4630-85fa-10727d12bc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sulai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sulai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sulai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sulai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    01 dec 2021 05:30 pm accident occurred thiruva...\n",
      "1    31 dec 2024 06:30 accident occurred thiruvanan...\n",
      "2    24 dec 2024 08:45 accident occurred thiruvanan...\n",
      "3    01 jan 2023 02:15 pm accident occurred thiruva...\n",
      "4    17 jan 2024 05:45 pm accident occurred thiruva...\n",
      "Name: Cleaned Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data files (only need to do this once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sulai\\Downloads\\final_accident_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data files (only need to do this once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation except for specific characters (e.g., ':')\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation.replace(':', '')))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Keep numbers and FIR numbers (e.g., P21, P18)\n",
    "    tokens = [word for word in tokens if re.match(r'\\d+|p\\d+|:\\d+|[a-zA-Z]+', word)]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the cleaning function to the unstructured text column\n",
    "df['Cleaned Text'] = df['Unstructured Text'].apply(clean_text)\n",
    "\n",
    "# Save the cleaned data back to the same CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Example of cleaned text\n",
    "print(df['Cleaned Text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d9f0412-b006-4652-9159-c21e321927ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add <start> and <end> tokens to the cleaned text and recommendation columns\n",
    "df['Cleaned Text'] = df['Cleaned Text'].apply(lambda x: '<start> ' + x + ' <end>')\n",
    "df['Recommendation'] = df['Recommendation'].apply(lambda x: '<start> ' + x + ' <end>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a08cfbb9-6936-4156-8d12-5f9179015571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenizer for input (Cleaned Text) and output (Recommendation)\n",
    "tokenizer = Tokenizer(oov_token='<unk>')\n",
    "tokenizer.fit_on_texts(df['Cleaned Text'].tolist() + df['Recommendation'].tolist())\n",
    "\n",
    "# Convert text to sequences\n",
    "input_sequences = tokenizer.texts_to_sequences(df['Cleaned Text'])\n",
    "output_sequences = tokenizer.texts_to_sequences(df['Recommendation'])\n",
    "\n",
    "# Padding sequences\n",
    "max_len_input = 200  # Max length for input sequences\n",
    "max_len_output = 50  # Max length for output sequences\n",
    "input_padded = pad_sequences(input_sequences, maxlen=max_len_input, padding='post', truncating='post')\n",
    "output_padded = pad_sequences(output_sequences, maxlen=max_len_output, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de23d9fe-5528-4667-bc5b-7d21ba15ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_padded, output_padded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3327514-b2b0-456e-87ef-8289da7020ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">411,900</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">411,900</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]        │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]        │                 │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4119</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,058,583</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │         \u001b[38;5;34m411,900\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │         \u001b[38;5;34m411,900\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │         \u001b[38;5;34m365,568\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│                               │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]        │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,  │         \u001b[38;5;34m365,568\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                               │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]        │                 │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m4119\u001b[0m)          │       \u001b[38;5;34m1,058,583\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,613,519</span> (9.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,613,519\u001b[0m (9.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,789,719</span> (6.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,789,719\u001b[0m (6.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">823,800</span> (3.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m823,800\u001b[0m (3.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 378ms/step - loss: 4.9468 - val_loss: 0.4753\n",
      "Epoch 2/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 363ms/step - loss: 0.4415 - val_loss: 0.3441\n",
      "Epoch 3/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 370ms/step - loss: 0.3241 - val_loss: 0.2419\n",
      "Epoch 4/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 352ms/step - loss: 0.2234 - val_loss: 0.1485\n",
      "Epoch 5/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 327ms/step - loss: 0.1361 - val_loss: 0.0926\n",
      "Epoch 6/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 330ms/step - loss: 0.0890 - val_loss: 0.0640\n",
      "Epoch 7/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 328ms/step - loss: 0.0625 - val_loss: 0.0489\n",
      "Epoch 8/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 320ms/step - loss: 0.0479 - val_loss: 0.0381\n",
      "Epoch 9/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 336ms/step - loss: 0.0369 - val_loss: 0.0325\n",
      "Epoch 10/10\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 345ms/step - loss: 0.0334 - val_loss: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "import pickle\n",
    "\n",
    "# Load GloVe embeddings\n",
    "glove_file = r\"C:\\Users\\sulai\\Downloads\\NLP\\glove.6B.100d.txt\"\n",
    "embeddings_index = {}\n",
    "with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "# Create embedding matrix\n",
    "embedding_dim = 100  # Dimension of GloVe embeddings\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in embeddings_index:\n",
    "        embedding_matrix[i] = embeddings_index[word]\n",
    "\n",
    "# Define the model\n",
    "embedding_dim = 100  # Embedding dimension\n",
    "lstm_units = 256  # Number of LSTM units\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_len_input,))\n",
    "enc_emb = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)(encoder_inputs)\n",
    "encoder_lstm = LSTM(lstm_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_len_output - 1,))\n",
    "dec_emb = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)(decoder_inputs)\n",
    "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "# Prepare decoder input and output sequences\n",
    "decoder_input_data = output_padded[:, :-1]  # Exclude the last token\n",
    "decoder_output_data = output_padded[:, 1:]  # Exclude the first token\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train, decoder_input_data], \n",
    "    decoder_output_data, \n",
    "    epochs=10, \n",
    "    batch_size=64, \n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save('lstm_model.h5')\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5819c18-1bc8-405e-93a3-42ddc90d284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have trained your model and it is stored in the variable `model`\n",
    "model.save('lstm_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dcc6153-b1f0-4eee-97f6-22baba8f5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define encoder and decoder models for inference\n",
    "encoder_model_inf = Model(encoder_inputs, [state_h, state_c])\n",
    "\n",
    "decoder_state_input_h = Input(shape=(lstm_units,))\n",
    "decoder_state_input_c = Input(shape=(lstm_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(dec_emb, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model_inf = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3cab891-6f28-4a30-8a9c-2c2b10f1f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "patterns = {\n",
    "    'District': r'\\b(thiruvananthapuram city)\\b',\n",
    "    'PS Name': r'\\b(vattiyoorkavu|vanchiyoor)\\b',\n",
    "    'Date Report': r'\\b(\\d{2} [a-z]{3} \\d{4})\\b',\n",
    "    'Date Accident': r'\\b(\\d{2} [a-z]{3} \\d{4})\\b',\n",
    "    'Time Accident': r'\\b(\\d{1,2}:\\d{2} (?:am|pm))\\b',\n",
    "    'Accident type': r'\\baccident type (\\w+ injury|fatal)\\b',\n",
    "    'Death': r'\\b(\\d+) fatalities\\b',\n",
    "    'Grievous': r'\\b(\\d+) grievous injuries\\b',\n",
    "    'Minor': r'\\b(\\d+) minor injuries\\b',\n",
    "    'Pedestrian': r'\\b(\\d+) pedestrian\\b',\n",
    "    'Cyclist': r'\\b(\\d+) cyclist\\b',\n",
    "    'Place of Occurance': r'\\baccident took place (\\w+)\\b',\n",
    "    'Type Area': r'\\b(\\w+) area\\b',\n",
    "    'City/Town/Village': r'\\b(\\w+) (?:city|town|village)\\b',\n",
    "    'Lanes Road': r'\\b(\\w+) lanes\\b',\n",
    "    'Divider': r'\\bdivider (\\w+)\\b',\n",
    "    'Spot Accident': r'\\bspot classification (\\w+)\\b',\n",
    "    'Weather': r'\\bweather conditions (\\w+)\\b',\n",
    "    'Collision': r'\\bcollision (\\w+)\\b',\n",
    "    'Type Road': r'\\broad type (\\w+)\\b',\n",
    "    'Road Features': r'\\bfeatures (\\w+)\\b',\n",
    "    'Visibility': r'\\bvisibility (\\w+)\\b',\n",
    "    'Traffic Control': r'\\btraffic control scene (\\w+)\\b',\n",
    "    'Accussed Vehicle': r'\\baccident involved (\\w+)\\b',\n",
    "    'Victim Vehicle': r'\\b(\\w+) vehicle\\b',\n",
    "    'Recommendation': r'\\brecommendation (.+?)\\b'\n",
    "}\n",
    "\n",
    "with open('regex_patterns.json', 'w') as f:\n",
    "    json.dump(patterns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79a060d1-db49-4a08-98c6-58181ad21244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              District: thiruvananthapuram city\\nPS Name: vattiyoorkavu\\nDate Report: 01 dec 2021\\nDate Accident: 01 dec 2021\\nTime Accident: 05:30 pm\\nAccident type: minor injury\\nDeath: 0\\nGrievous: 0\\nMinor: 2\\nPlace of Occurance: moothakunnam\\nCity/Town/Village: thiruvananthapuram\\nSpot Accident: near\\nWeather: sunnyclear\\nType Road: national\\nRoad Features: straight\\nVisibility: road\\nTraffic Control: uncontrolled\\nAccussed Vehicle: tipper\\nRecommendation: improve\n",
      "1                                               District: thiruvananthapuram city\\nPS Name: vanchiyoor\\nDate Report: 31 dec 2024\\nDate Accident: 31 dec 2024\\nAccident type: fatal\\nDeath: 1\\nGrievous: 0\\nMinor: 0\\nPlace of Occurance: kavilnada\\nCity/Town/Village: thiruvananthapuram\\nSpot Accident: pedestrian\\nWeather: sunnyclear\\nType Road: national\\nRoad Features: straight\\nVisibility: road\\nTraffic Control: uncontrolled\\nAccussed Vehicle: motor\\nRecommendation: improve\n",
      "2    District: thiruvananthapuram city\\nPS Name: vanchiyoor\\nDate Report: 24 dec 2024\\nDate Accident: 24 dec 2024\\nAccident type: grevious injury\\nDeath: 0\\nGrievous: 1\\nMinor: 0\\nPlace of Occurance: vazhakulam\\nType Area: marketcommercial\\nCity/Town/Village: thiruvananthapuram\\nSpot Accident: marketcommercial\\nWeather: sunnyclear\\nType Road: state\\nRoad Features: straight\\nVisibility: road\\nTraffic Control: uncontrolled\\nAccussed Vehicle: motor\\nRecommendation: improve\n",
      "3                                     District: thiruvananthapuram city\\nPS Name: vanchiyoor\\nTime Accident: 02:15 pm\\nAccident type: grevious injury\\nDeath: 0\\nGrievous: 1\\nMinor: 0\\nPlace of Occurance: perumattam\\nType Area: marketcommercial\\nCity/Town/Village: thiruvananthapuram\\nSpot Accident: marketcommercial\\nWeather: sunnyclear\\nType Road: road\\nRoad Features: curved\\nVisibility: road\\nTraffic Control: uncontrolled\\nAccussed Vehicle: auto\\nRecommendation: improve\n",
      "4                                                                                District: thiruvananthapuram city\\nPS Name: vanchiyoor\\nTime Accident: 05:45 pm\\nAccident type: grevious injury\\nDeath: 0\\nGrievous: 1\\nMinor: 1\\nPlace of Occurance: near\\nCity/Town/Village: thiruvananthapuram\\nSpot Accident: near\\nWeather: sunnyclear\\nType Road: state\\nRoad Features: straight\\nVisibility: road\\nTraffic Control: uncontrolled\\nAccussed Vehicle: motor\\nRecommendation: improve\n",
      "Name: Formatted Summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def extract_info(text, patterns):\n",
    "    info = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            try:\n",
    "                info[key] = match.group(1).strip()  # Capture the actual data\n",
    "            except IndexError:\n",
    "                print(f\"Error in pattern for {key}: {pattern}\")\n",
    "                print(f\"Text: {text}\")\n",
    "                info[key] = None\n",
    "        else:\n",
    "            info[key] = None\n",
    "    return info\n",
    "\n",
    "# Apply the extraction function to each row in the DataFrame\n",
    "df['Summary'] = df['Cleaned Text'].apply(lambda x: extract_info(x, patterns))\n",
    "\n",
    "# Format the extracted information into a summary\n",
    "def format_summary(summary):\n",
    "    formatted_summary = []\n",
    "    for key, value in summary.items():\n",
    "        if value:\n",
    "            formatted_summary.append(f\"{key}: {value}\")\n",
    "    return \"\\n\".join(formatted_summary)\n",
    "\n",
    "# Apply the formatting function to each summary\n",
    "df['Formatted Summary'] = df['Summary'].apply(format_summary)\n",
    "\n",
    "# Adjust display settings to show full content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Print the summaries\n",
    "print(df['Formatted Summary'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fa06f1f-ca4d-47f9-a842-8785aaf718e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                        <start> 01 dec 2021 05:30 pm accident occurred thiruvananthapuram city jurisdiction vattiyoorkavu police station accident type minor injury 0 fatalities 0 grievous injuries 2 minor injuries accident took place moothakunnam rural weather conditions sunnyclear good visibility road type national highway features straight road accident involved tipper motor cycle spot classification near bus stop traffic control scene uncontrolled recommendation improve general road safety awareness enforcement <end>\n",
      "1    <start> 31 dec 2024 06:30 accident occurred thiruvananthapuram city jurisdiction vanchiyoor police station accident type fatal 1 fatalities 0 grievous injuries 0 minor injuries accident took place kavilnada rural weather conditions sunnyclear good visibility road type national highway features straight road accident involved motor cycle motor cycle spot classification pedestrian crossing traffic control scene uncontrolled recommendation improve pedestrian crossings install better signage increase road safety measures emergency response times <end>\n",
      "2                                                       <start> 24 dec 2024 08:45 accident occurred thiruvananthapuram city jurisdiction vanchiyoor police station accident type grevious injury 0 fatalities 1 grievous injuries 0 minor injuries accident took place vazhakulam rural weather conditions sunnyclear good visibility road type state highway features straight road accident involved motor cycle scooter spot classification marketcommercial area traffic control scene uncontrolled recommendation improve general road safety awareness enforcement <end>\n",
      "3                                                         <start> 01 jan 2023 02:15 pm accident occurred thiruvananthapuram city jurisdiction vanchiyoor police station accident type grevious injury 0 fatalities 1 grievous injuries 0 minor injuries accident took place perumattam rural weather conditions sunnyclear good visibility road type road features curved road accident involved auto rickshaw motor cycle spot classification marketcommercial area traffic control scene uncontrolled recommendation improve general road safety awareness enforcement <end>\n",
      "4                                        <start> 17 jan 2024 05:45 pm accident occurred thiruvananthapuram city jurisdiction vanchiyoor police station accident type grevious injury 0 fatalities 1 grievous injuries 1 minor injuries accident took place near federal bank vazhakulam rural weather conditions sunnyclear good visibility road type state highway features straight road accident involved motor cycle car spot classification near office complex traffic control scene uncontrolled recommendation improve general road safety awareness enforcement <end>\n",
      "Name: Cleaned Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the cleaned text\n",
    "print(df['Cleaned Text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4382fe54-5c6a-4096-a2e1-1e0294f8816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Accident type: accident type\\nGrievous: grievo...\n",
      "1    Accident type: accident type\\nGrievous: grievo...\n",
      "2    Accident type: accident type\\nGrievous: grievo...\n",
      "3    Accident type: accident type\\nGrievous: grievo...\n",
      "4    Accident type: accident type\\nGrievous: grievo...\n",
      "Name: Formatted Summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Example of how to format the summary\n",
    "def format_summary(summary):\n",
    "    formatted_summary = []\n",
    "    for key, value in summary.items():\n",
    "        if value:\n",
    "            formatted_summary.append(f\"{key}: {value}\")\n",
    "    return \"\\n\".join(formatted_summary)\n",
    "\n",
    "# Apply the formatting function to each summary\n",
    "df['Formatted Summary'] = df['Summary'].apply(format_summary)\n",
    "\n",
    "# Display the first few summaries\n",
    "print(df['Formatted Summary'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5e6ef57-3fec-493f-af4f-4d5a4cc98bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                        Accident type: accident type\\nGrievous: grievous\\nMinor: minor\\nWeather: weather\\nVisibility: visibility\\nTraffic Control: traffic control\\nRecommendation: recommendation\n",
      "1                                Accident type: accident type\\nGrievous: grievous\\nMinor: minor\\nPedestrian: pedestrian\\nWeather: weather\\nVisibility: visibility\\nTraffic Control: traffic control\\nRecommendation: recommendation\n",
      "2                                                        Accident type: accident type\\nGrievous: grievous\\nMinor: minor\\nWeather: weather\\nVisibility: visibility\\nTraffic Control: traffic control\\nRecommendation: recommendation\n",
      "3    Accident type: accident type\\nGrievous: grievous\\nMinor: minor\\nWeather: weather\\nType Road: type road\\nRoad Features: road features\\nVisibility: visibility\\nTraffic Control: traffic control\\nRecommendation: recommendation\n",
      "4                                                        Accident type: accident type\\nGrievous: grievous\\nMinor: minor\\nWeather: weather\\nVisibility: visibility\\nTraffic Control: traffic control\\nRecommendation: recommendation\n",
      "Name: Formatted Summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the display option to show more characters in each cell\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None to display the full content\n",
    "\n",
    "# Now print the summaries\n",
    "print(df['Formatted Summary'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd5ae6-7e92-483c-ad5f-c3f0585fd022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpu_env]",
   "language": "python",
   "name": "conda-env-gpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
